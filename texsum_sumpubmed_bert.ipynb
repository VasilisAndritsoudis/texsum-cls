{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-27T20:03:34.726921500Z",
     "start_time": "2023-12-27T20:03:34.670916600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizerFast, BertModel\n",
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class SummarizationClassifier(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SummarizationClassifier, self).__init__()\n",
    "        self.base_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.dropout = torch.nn.Dropout(0.1)\n",
    "        self.linear = torch.nn.Linear(768, 2)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            self.device = torch.device(\"cuda\")\n",
    "        else:\n",
    "            self.device = torch.device(\"cpu\")\n",
    "        self.to(self.device)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        outputs = self.base_model(**inputs)\n",
    "        outputs = self.dropout(outputs[1])\n",
    "        outputs = self.linear(outputs)\n",
    "        \n",
    "        return self.sigmoid(outputs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T20:03:34.747917300Z",
     "start_time": "2023-12-27T20:03:34.702918700Z"
    }
   },
   "id": "6b64e2de886ca52c"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "model = SummarizationClassifier()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T20:03:56.556193700Z",
     "start_time": "2023-12-27T20:03:34.731918100Z"
    }
   },
   "id": "dd3a77cdb36612e6"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "f = open(\"data\\\\data_1.txt\", encoding=\"utf8\")\n",
    "data = f.read()\n",
    "f.close()\n",
    "inputs = tokenizer(data, max_length=512, truncation='longest_first', return_tensors=\"pt\")\n",
    "inputs.to(model.device)\n",
    "outputs = model(inputs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T20:04:05.447086800Z",
     "start_time": "2023-12-27T20:03:56.562198Z"
    }
   },
   "id": "9c4237955636de7a"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5604, 0.5640]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[0.4991, 0.5009]], device='cuda:0', grad_fn=<SoftmaxBackward0>)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(outputs)\n",
    "torch.nn.functional.softmax(outputs, dim=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T20:04:07.161251100Z",
     "start_time": "2023-12-27T20:04:05.445080600Z"
    }
   },
   "id": "3b29b92591e0da43"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
